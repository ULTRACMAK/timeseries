{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152fb1f-a6b6-4a5d-9ef9-7137589cff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e01e3d-a17e-43c2-b113-5f3a27499956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88459bf-191a-4830-ab2e-7acd6ca78a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('train.csv', nrows = 1_500_000, parse_dates=[\"pickup_datetime\"], index_col = ['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924e6c5-c492-4894-996e-14757be5a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ed11d-1ea1-4c6f-843f-a1366afed466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12009771-add0-463a-b95a-0fd10bd0448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4dd04-dea7-4a80-a3c5-6843ac7ec8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.passenger_count >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974753b-d807-48ff-be21-3800cd019105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fare_amount = abs(df.fare_amount)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a77706-3906-4449-a240-ae86c08e7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.fare_amount > 0]\n",
    "df = df[df.passenger_count <= 10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a9535-32b1-4080-9144-d43cee5c1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how = 'any', axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b039a-b343-4d8a-808d-dd3b2b9f3935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['year'] = df['pickup_datetime'].dt.year\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "df['hour'] =df['pickup_datetime'].dt.hour\n",
    "df['day'] = df['pickup_datetime'].dt.day\n",
    "#!pip install holidays\n",
    "from holidays import US\n",
    "holidays_us = US()\n",
    "df['is_holiday'] = df['pickup_datetime'].dt.date.apply(lambda x: x in holidays_us).astype(int)\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)  # Суббота и воскресенье\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['is_rushhour'] = df['hour'].isin([8, 18, 20, 19, 17, 21]).astype(int) \n",
    "df['time_period'] = pd.cut(df['hour'], \n",
    "                          bins=[-1, 6, 12, 18, 23],\n",
    "                          labels=[0, 1, 2, 3]) #вечер день\n",
    "df['season'] = pd.cut(df['month'],\n",
    "                     bins=[0, 3, 6, 9, 12],\n",
    "                     labels=[4,1, 2, 3])\n",
    "df.time_period = df.time_period.astype(int)\n",
    "df.season = df.season.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc9d01-e8ee-4bc2-9975-72b30bc483eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25b7d1-b7b0-4131-905e-203ddf8eab2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_density_heatmap(df):\n",
    "    density_maps = {}\n",
    "    for hour in range(24):\n",
    "        hour_data = df[df['hour'] == hour]\n",
    "        heatmap, _, _ = np.histogram2d(\n",
    "            hour_data['pickup_latitude'], \n",
    "            hour_data['pickup_longitude'], \n",
    "        )\n",
    "        density_maps[hour] = heatmap\n",
    "    return density_maps\n",
    "def plot_density_heatmap(df, figsize=(15, 10)):\n",
    "    density_maps = create_density_heatmap(df)\n",
    "    fig, axes = plt.subplots(4, 6, figsize=figsize)\n",
    "    axes = axes.ravel()\n",
    "    for hour, heatmap in density_maps.items():\n",
    "        ax = axes[hour]\n",
    "        sns.heatmap(heatmap, ax=ax, cmap='YlOrRd')\n",
    "        ax.set_title(f'Hour {hour}')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "fig = plot_density_heatmap(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad978e9-c00e-416b-bea8-037db98aeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install reverse_geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9c7ac-8ab5-4534-8ff2-b733c248cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58fc6d-3ddb-4a4f-b682-6684af0d3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n",
    "NYC_CENTER = (40.7128, -74.0060)  # Manhattan center\n",
    "JFK_AIRPORT = (40.6413, -73.7781)\n",
    "LGA_AIRPORT = (40.7769, -73.8740)\n",
    "EWR_AIRPORT = (40.6895, -74.1745)\n",
    "def create_distance_features(df):\n",
    "\n",
    "    df['pickup_dist_to_center'] = df.apply(lambda row: \n",
    "        geodesic((row['pickup_latitude'], row['pickup_longitude']), NYC_CENTER).miles, axis=1)\n",
    "    df['pickup_dist_to_jfk'] = df.apply(lambda row: \n",
    "        geodesic((row['pickup_latitude'], row['pickup_longitude']), JFK_AIRPORT).miles, axis=1)\n",
    "    df['pickup_dist_to_lga'] = df.apply(lambda row: \n",
    "        geodesic((row['pickup_latitude'], row['pickup_longitude']), LGA_AIRPORT).miles, axis=1)\n",
    "    df['pickup_dist_to_ewr'] = df.apply(lambda row: \n",
    "        geodesic((row['pickup_latitude'], row['pickup_longitude']), EWR_AIRPORT).miles, axis=1)\n",
    "    # to EWR\n",
    "   \n",
    "    df['dropoff_dist_to_center'] = df.apply(lambda row: \n",
    "        geodesic((row['dropoff_latitude'], row['dropoff_longitude']), NYC_CENTER).miles, axis=1)\n",
    "    df['dropoff_dist_to_jfk'] = df.apply(lambda row: \n",
    "        geodesic((row['dropoff_latitude'], row['dropoff_longitude']), JFK_AIRPORT).miles, axis=1)\n",
    "    df['dropoff_dist_to_lga'] = df.apply(lambda row: \n",
    "        geodesic((row['dropoff_latitude'], row['dropoff_longitude']), LGA_AIRPORT).miles, axis=1)\n",
    "    df['dropoff_dist_to_ewr'] = df.apply(lambda row: \n",
    "        geodesic((row['dropoff_latitude'], row['dropoff_longitude']), EWR_AIRPORT).miles, axis=1)\n",
    "    \n",
    "    df['trip_distance'] = df.apply(lambda row: \n",
    "        geodesic(\n",
    "            (row['pickup_latitude'], row['pickup_longitude']),\n",
    "            (row['dropoff_latitude'], row['dropoff_longitude'])\n",
    "        ).miles, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8476b-930b-4e02-984e-27615934548c",
   "metadata": {},
   "source": [
    "килерфичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc916353-5d6a-47e5-8e6e-06ed4ed493e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_administrative_areas(df):\n",
    "    # Reverse geocoding\n",
    "    coordinates = df[['latitude', 'longitude']].values\n",
    "    results = rg.search(coordinates)\n",
    "    \n",
    "    df['admin_area'] = [result['admin1'] for result in results]\n",
    "    df['city'] = [result['name'] for result in results]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2077d-45bb-4945-aaeb-14e4f49279f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_metric(df):\n",
    "    # to UTM coordinates (meters)\n",
    "    transformer = Transformer.from_crs('EPSG:4326', 'EPSG:32618', always_xy=True)\n",
    "    \n",
    "    meters_east, meters_north = transformer.transform(\n",
    "        df['longitude'].values, \n",
    "        df['latitude'].values\n",
    "    )\n",
    "    df['meters_east'] = meters_east\n",
    "    df['meters_north'] = meters_north\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147eb31c-0e32-4c95-8514-dd5bf72020bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' если много неправильных а так дроп\n",
    "    df[lat_col] = df[lat_col] % 180\n",
    "    df.loc[df[lat_col] > 90, lat_col] = 180 - df.loc[df[lat_col] > 90, lat_col]\n",
    "    df.loc[df[lat_col] < -90, lat_col] = -180 - df.loc[df[lat_col] < -90, lat_col]\n",
    "    df[lon_col] = ((df[lon_col] + 180) % 360) - 180\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a8777-ce82-4d6d-abaf-b0ddb7402994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nyc_coordinates(df, lat_col='latitude', lon_col='longitude'):\n",
    "    \"\"\"\n",
    "    Filter coordinates to NYC area\n",
    "    NYC Bounding Box:\n",
    "    Latitude: 40.477399 to 40.917577\n",
    "    Longitude: -74.259090 to -73.700272\n",
    "    \"\"\"\n",
    "    nyc_mask = (\n",
    "        (df[lat_col] >= 40.477399) & \n",
    "        (df[lat_col] <= 40.917577) & \n",
    "        (df[lon_col] >= -74.259090) & \n",
    "        (df[lon_col] <= -73.700272)\n",
    "    )\n",
    "    \n",
    "    return df[nyc_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83957936-ebf1-41ac-a88b-d1c591256f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h3_feature(df, lat_col, lon_col, resolution=7):\n",
    "    \"\"\" \n",
    "    resolution: H3 resolution (0-15), default 7\n",
    "    Чем выше resolution, тем более детальное разбиение пространства\n",
    "    7-8 для городского масштаба\n",
    "5-6 для регионов\n",
    "3-4 страны\n",
    "    \"\"\"\n",
    "    df['h3_index'] = df.apply(\n",
    "        lambda row: h3.geo_to_h3(row[lat_col], row[lon_col], resolution), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Создаем one-hot encoding\n",
    "    h3_encoded = pd.get_dummies(df['h3_index'], prefix='h3_zone')\n",
    "    \n",
    "    # Объединяем с исходным датафреймом\n",
    "    result_df = pd.concat([df, h3_encoded], axis=1)\n",
    "    \n",
    "    # Удаляем промежуточный столбец с H3 индексами\n",
    "    result_df.drop('h3_index', axis=1, inplace=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58225994-2fca-4a27-a813-6eedca1917c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rasterio\n",
    "from rasterio.warp import transform\n",
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class TerrainEnrichment:\n",
    "    def __init__(self):\n",
    "        # Инициализация Google Earth Engine\n",
    "        ee.Initialize()\n",
    "        \n",
    "    def get_elevation(self, df, lat_col='latitude', lon_col='longitude'):\n",
    "        \"\"\"\n",
    "        Получает высоту над уровнем моря используя Open-Elevation API\n",
    "        \"\"\"\n",
    "        elevations = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            url = f\"https://api.open-elevation.com/api/v1/lookup?locations={row[lat_col]},{row[lon_col]}\"\n",
    "            response = requests.get(url).json()\n",
    "            elevation = response['results'][0]['elevation']\n",
    "            elevations.append(elevation)\n",
    "            \n",
    "        df['elevation'] = elevations\n",
    "        \n",
    "        # Добавляем производные признаки\n",
    "        df['elevation_category'] = pd.cut(df['elevation'],\n",
    "                                        bins=[-np.inf, 0, 200, 500, 1000, np.inf],\n",
    "                                        labels=['sea_level', 'lowland', 'upland', 'highland', 'mountain'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_landcover(self, df, lat_col='latitude', lon_col='longitude'):\n",
    "        \"\"\"\n",
    "        Получает тип земной поверхности используя Google Earth Engine\n",
    "        \"\"\"\n",
    "        # Загружаем датасет землепользования ESA\n",
    "        dataset = ee.ImageCollection('ESA/WorldCover/v100').first()\n",
    "        \n",
    "        landcover_types = []\n",
    "        urban_density = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            point = ee.Geometry.Point([row[lon_col], row[lat_col]])\n",
    "            \n",
    "            # Получаем тип поверхности\n",
    "            landcover = dataset.sample(point, 30).first().get('Map').getInfo()\n",
    "            landcover_types.append(self._decode_landcover(landcover))\n",
    "            \n",
    "            # Рассчитываем плотность городской застройки в радиусе 1км\n",
    "            buffer = point.buffer(1000)\n",
    "            urban_pixels = dataset.select('Map').eq(50).reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=buffer,\n",
    "                scale=30\n",
    "            ).get('Map').getInfo()\n",
    "            \n",
    "            urban_density.append(urban_pixels)\n",
    "        \n",
    "        df['landcover_type'] = landcover_types\n",
    "        df['urban_density'] = urban_density\n",
    "        \n",
    "        # Добавляем признак природной зоны\n",
    "        df['nature_zone'] = self._calculate_nature_zone(df[lat_col])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _decode_landcover(self, code):\n",
    "        \"\"\"\n",
    "        Декодирует коды типов поверхности ESA WorldCover\n",
    "        \"\"\"\n",
    "        landcover_dict = {\n",
    "            10: 'tree_cover',\n",
    "            20: 'shrubland',\n",
    "            30: 'grassland',\n",
    "            40: 'cropland',\n",
    "            50: 'built_up',\n",
    "            60: 'bare_ground',\n",
    "            70: 'snow_ice',\n",
    "            80: 'water',\n",
    "            90: 'wetland'\n",
    "        }\n",
    "        return landcover_dict.get(code, 'unknown')\n",
    "    \n",
    "    def _calculate_nature_zone(self, latitude):\n",
    "        \"\"\"\n",
    "        Определяет природную зону на основе широты\n",
    "        \"\"\"\n",
    "        zones = pd.cut(abs(latitude),\n",
    "                      bins=[0, 23.5, 35, 55, 66.5, 90],\n",
    "                      labels=['tropical', 'subtropical', 'temperate', 'subarctic', 'arctic'])\n",
    "        return zones\n",
    "        \n",
    "# Пример использования\n",
    "data = {\n",
    "        'latitude': [55.7558, 55.7522, 55.7539],\n",
    "        'longitude': [37.6173, 37.6156, 37.6208]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "enricher = TerrainEnrichment()\n",
    "df = enricher.get_elevation(df)\n",
    "df = enricher.get_landcover(df)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309fbbf-aea6-4395-a599-a26224b9b3b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102203c5-a78b-48cb-9b62-1c9056854107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pickup_latitude'] <= 90]\n",
    "df = df[df['dropoff_latitude'] <= 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e013e6a-83ab-4b5a-acc2-24fbefe9603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pickup_latitude'] >= -90]\n",
    "df = df[df['dropoff_latitude'] >= -90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cdef59-c69d-47b3-b69a-3b8d86f8ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_distance_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d26e9f-333d-4720-b6dc-5bed16b02af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98d09d-8550-4f3a-8093-cc5ed8f87f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(name='name', colors=['green','yellow','red'])\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "points = ax.scatter(df['pickup_longitude'], df['pickup_latitude'], c=df['fare_amount'],\n",
    "                     cmap=cmap)\n",
    "f.colorbar(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd820b1c-9e42-42ce-ac3e-690a96fe0a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(name='name', colors=['green','yellow','red'])\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "points = ax.scatter(df['dropoff_longitude'], df['dropoff_latitude'], c=df['fare_amount'], cmap=cmap)\n",
    "f.colorbar(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51531ba2-b50d-4f91-b60e-7a66b3c23a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_features(df):\n",
    "    pickup_lat_rad = np.radians(df['pickup_latitude'])\n",
    "    pickup_lon_rad = np.radians(df['pickup_longitude'])\n",
    "    dropoff_lat_rad = np.radians(df['dropoff_latitude'])\n",
    "    dropoff_lon_rad = np.radians(df['dropoff_longitude'])\n",
    "    \n",
    "    y = np.sin(dropoff_lon_rad - pickup_lon_rad) * np.cos(dropoff_lat_rad)\n",
    "    x = np.cos(pickup_lat_rad) * np.sin(dropoff_lat_rad) - \\\n",
    "        np.sin(pickup_lat_rad) * np.cos(dropoff_lat_rad) * np.cos(dropoff_lon_rad - pickup_lon_rad)\n",
    "    bearing = np.arctan2(y, x)\n",
    "    \n",
    "    df['travel_bearing'] = np.degrees(bearing) \n",
    "    df['travel_bearing_sin'] = np.sin(bearing)\n",
    "    df['travel_bearing_cos'] = np.cos(bearing)\n",
    "    \n",
    "    df['travel_vector_magnitude'] = np.sqrt(\n",
    "        (df['dropoff_latitude'] - df['pickup_latitude'])**2 + \n",
    "        (df['dropoff_longitude'] - df['pickup_longitude'])**2\n",
    "    )\n",
    "    \n",
    "    df['travel_ns_component'] = df['dropoff_latitude'] - df['pickup_latitude']\n",
    "    df['travel_ew_component'] = df['dropoff_longitude'] - df['pickup_longitude']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7594766-5118-4710-a1d6-092188b8f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_vector_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1918bf-5a37-4c5b-b714-cc99dfec65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def create_dbscan_clusters(df, eps=0.3, min_samples=5):\n",
    "    coords = df[['pickup_latitude', 'pickup_longitude']].values\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)\n",
    "    df['cluster_id'] = clustering.labels_\n",
    "    return df\n",
    "# Кластеризация K-средних\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "data['cluster'] = kmeans.fit_predict(data[['latitude', 'longitude']])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc5b5c-4e15-4d1e-8538-abc0832d3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = create_dbscan_clusters(df) - memory limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d804d5-7c18-4ce4-a7eb-8e5e47a80759",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "df['fare_amount'].plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('fare_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80c4c6-72b4-4624-a3d2-795d59740333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd35e6-3696-47ce-9021-4699e2548587",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test (2).csv', parse_dates=[\"pickup_datetime\"],index_col = ['key'])\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706119e-6f30-46e5-b572-8ba64468dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "test.index = pd.to_datetime(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac187596-fafc-4935-bcaf-dde2db938f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(test.index.unique()) - set(df.index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98032b17-1d31-4092-af0c-9c1e1de79be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "monthly_df = pd.DataFrame()\n",
    "monthly_df['fare_amount'] = df['fare_amount'].resample('MS').mean()\n",
    "plt.plot(monthly_df.index, monthly_df.fare_amount, linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec80c4b-2407-47a1-b4bf-6ec15dbf8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6c6b4-f21a-401d-a2fc-1dd5483bd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(monthly_df['fare_amount'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d23027-d781-4b51-a231-78250298e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca50bf-acc7-41c2-b8de-1e97f42b313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "test = test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f9c56-367e-41fd-b60f-fb90515e2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df['rolling_mean_7d'] = df['fare_amount'].rolling('7D').mean()\n",
    "df['rolling_mean_24h'] = df['fare_amount'].rolling('24H').mean()\n",
    "\n",
    "df['rolling_sum_7d'] = df['fare_amount'].rolling('7D').sum()\n",
    "df['rolling_sum_24h'] = df['fare_amount'].rolling('24H').sum()\n",
    "\n",
    "df['rolling_max_7d'] = df['fare_amount'].rolling('7D').max()\n",
    "df['rolling_max_24h'] = df['fare_amount'].rolling('24H').max()\n",
    "\n",
    "df['rolling_min_7d'] = df['fare_amount'].rolling('7D').min()\n",
    "df['rolling_min_24h'] = df['fare_amount'].rolling('24H').min()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55bfc8-1ec4-438c-87b0-5f7669b89070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.unique().max(), test.index.unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe831b1-7a2f-43f3-a30a-2e9e45d3f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d19b18-9ae4-4bd9-bc7c-4f8ff6b6188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test['pickup_datetime'].dt.year\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day_of_week'] = test['pickup_datetime'].dt.dayofweek\n",
    "test['hour'] =test['pickup_datetime'].dt.hour\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['is_holiday'] = test['pickup_datetime'].dt.date.apply(lambda x: x in holidays_us).astype(int)\n",
    "test['is_weekend'] = test['day_of_week'].isin([5, 6]).astype(int)  # Суббота и воскресенье\n",
    "test['hour_sin'] = np.sin(2 * np.pi * test['hour'] / 24)\n",
    "test['hour_cos'] = np.cos(2 * np.pi * test['hour'] / 24)\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)\n",
    "test['is_rushhour'] = test['hour'].isin([8, 18, 20, 19, 17, 21]).astype(int) \n",
    "test['time_period'] = pd.cut(test['hour'], \n",
    "                          bins=[-1, 6, 12, 18, 23],\n",
    "                          labels=[0, 1, 2, 3]) #вечер день\n",
    "test['season'] = pd.cut(test['month'],\n",
    "                     bins=[0, 3, 6, 9, 12],\n",
    "                     labels=[4,1, 2, 3])\n",
    "test.time_period = test.time_period.astype(int)\n",
    "test.season = test.season.astype(int)\n",
    "test = create_distance_features(test)\n",
    "test = create_vector_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724d943-aefe-4173-9b6e-3c37c8db4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803b46b-dfbb-438a-954f-3a065469ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377cc54-d12f-4ff5-99c7-b5c1fc8060a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7ca03-1680-40d5-9e9d-3968baeb4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f06a8c-5529-4ba2-af7c-623e2618f6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f86fa-3efa-4772-a5ca-51e756c96c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2b1bd-4a9e-425e-a940-3cf1ce08890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6ca25-ed59-4590-858f-dbc29006c47f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_rolling_means(train_df, test_df, time_column='time_key', value_column='fare_amount'):\n",
    "\n",
    "    train_df['is_train'] = True\n",
    "    test_df['is_train'] = False\n",
    "    \n",
    "    combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "    combined_df = combined_df.sort_values(time_column)\n",
    "\n",
    "    three_hours = pd.Timedelta(hours=3)\n",
    "    three_days = pd.Timedelta(days=3)\n",
    "\n",
    "    train_data = combined_df[combined_df['is_train']][[time_column, value_column]]\n",
    "    combined_df['rolling_mean_3h'] = train_data.rolling(\n",
    "        window=three_hours,\n",
    "        min_periods=1,\n",
    "        closed='left',\n",
    "        on=time_column\n",
    "    ).mean()['fare_amount']\n",
    "    \n",
    "    combined_df['rolling_mean_3d'] = train_data.rolling(\n",
    "        window=three_days,\n",
    "        min_periods=1,\n",
    "        closed='left',\n",
    "        on=time_column\n",
    "    ).mean()['fare_amount']\n",
    "    \n",
    "    train_processed = combined_df[combined_df['is_train']].drop('is_train', axis=1)\n",
    "    test_processed = combined_df[~combined_df['is_train']].drop('is_train', axis=1)\n",
    "    \n",
    "    return train_processed, test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d69cf-54b5-4b38-97c1-f8bfdb243b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = calculate_rolling_means(df,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948303c-b6c6-45db-a04f-df7761466b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf2508-7c9f-435c-8bf5-c580b5df844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['fare_amount'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4700e-3692-4211-97a1-12778669bb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8891d-c701-4966-bf2e-f39a3cf23163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rolling_mean_3h.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664685ce-549c-4f09-a641-dedbe07ec906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['rolling_mean_3h'] = train['rolling_mean_3h'].fillna(train.rolling_mean_3h.mean())\n",
    "#test['rolling_mean_3d'] = train['rolling_mean_3d'].fillna(9.695963242861593)\n",
    "test['rolling_mean_3h'] = test['rolling_mean_3h'].fillna(9.72152837095675)\n",
    "test['rolling_mean_3d'] = test['rolling_mean_3d'].fillna(9.695963242861593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06e49b-6a9c-4dea-9885-06cecd60ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "def extract_time_components(train_df, test_df, time_column='time_key', target_column='fare_amount'):\n",
    "    train_ts = train_df.set_index(time_column).resample('H')[target_column].mean().fillna(method='ffill')\n",
    "    stl = STL(train_ts, period=24)\n",
    "    result = stl.fit()\n",
    "    \n",
    "    train_components = pd.DataFrame(index=train_ts.index)\n",
    "    train_components['trend'] = result.trend\n",
    "    train_components['seasonal'] = result.seasonal\n",
    "    \n",
    "    seasonal_pattern = result.seasonal.values[:24]\n",
    "    train_df['seasonal'] = train_df['hour'].map(dict(enumerate(seasonal_pattern)))\n",
    "    test_df['seasonal'] = test_df['hour'].map(dict(enumerate(seasonal_pattern)))\n",
    "    \n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9717c-c67d-466b-9470-bfb3bd201d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45bab8-2f26-4dca-ac01-16a167e99561",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = extract_time_components(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad84305-8ca8-4aaa-9a41-15c6b36049ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557c818-54b9-4361-bc88-82bb76713549",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('df_clear.csv')\n",
    "test.to_csv('test_clear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856c710-98a1-4a5d-a7d4-84a540a85979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = train.corr()\n",
    "corr['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe62f07-e18e-4e4d-bd2f-4a8611f5d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error\n",
    "#!pip install catboost\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe62180-f277-4513-beb8-3bbf84d0a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33014fb-d97b-4a70-886c-ef4e5d9da031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f51604-f977-4050-a1b6-c982655df71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor()\n",
    "x = train.drop(columns = ['fare_amount', 'time_key', 'rolling_mean_3d', 'pickup_datetime'])\n",
    "y = train['fare_amount']\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbe287-9220-428a-99e4-e13cd0ee6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = ['rolling_mean_3d'],inplace = True) #\"['pickup_datetime', 'time_key'] not found in axis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd122c9-2a51-43bb-9516-f74e496c82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('sample_submission (2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bff96-9208-4ec2-b1a2-416da92350f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa713f-393f-45d3-a9ae-1db1a4764a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['fare_amount'] = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f4dd0-c08b-430e-b496-12fa99970cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('subm2.csv',sep = ',',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda16188-0c3a-44cc-89a8-929ddbe824bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mda catboost podkachal nu nichego, best score without rolling and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70264b3c-5b9f-4c99-a74c-3b651f3c1ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cf7d1-c3ef-426c-8595-cfadab554530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.drop(columns = ['rolling_mean_3h' , 'rolling_mean_3d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb500fd-0f92-4ab8-b4c4-a031e46d38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.drop(columns = ['rolling_mean_3h'])\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6260c-d0e5-4688-bfe6-70d3b31620f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd418bd6-005b-407a-9e25-2a2027236486",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5c094-1d90-430a-8be3-d8f4ce855e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.mx import SimpleFeedForwardEstimator, Trainer\n",
    "estimator = SimpleFeedForwardEstimator(\n",
    "    num_hidden_dimensions=[10],\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=100,\n",
    "    trainer=Trainer(ctx=\"cpu\", epochs=5, learning_rate=1e-3, num_batches_per_epoch=100),\n",
    " #https://ts.gluon.ai/stable/tutorials/forecasting/quick_start_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d689413-c6da-49c3-b7d7-07578b66d3e9",
   "metadata": {},
   "source": [
    "ПРОВЕРИМ НА СТАЦИОНАРНОСТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df03d8-f730-495a-b749-6a9f3fd6fc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1 = train1.set_index('time_key')\n",
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457728a-b656-4265-8fdf-4dc36bdf5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369b815-7442-4cda-b106-918aa8fcfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.index = pd.to_datetime(train1.index)\n",
    "monthly_OS = pd.DataFrame()\n",
    "monthly_OS['fare_amount'] = train1['fare_amount'].resample('MS').mean()\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "print ('Results of Dickey-Fuller Test:')\n",
    "dftest = adfuller(monthly_OS, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print (dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef60eb8-610c-438e-9824-ca405fc9e2c5",
   "metadata": {},
   "source": [
    "ужасно нестационарные данные, p - value должен быть 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e7d9c-a8ea-4376-8597-71fd41aecbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "do = train1['fare_amount']\n",
    "do = do.reset_index()\n",
    "do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930a261-6939-4d2f-971a-c92e2dcd9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "do = do.groupby('time_key')['fare_amount'].sum().reset_index()\n",
    "do = do.set_index('time_key')\n",
    "do.index = pd.to_datetime(do.index)\n",
    "yy = do['fare_amount'].resample('MS').mean()\n",
    "ts_log = np.log(yy)\n",
    "plt.plot(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc104bb-7ce6-4d87-8efa-4a9fe48a465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1['fare_amount'] = np.log(train1['fare_amount'])\n",
    "train1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469b6b0-9e6f-4181-be5a-0a76bb7061ae",
   "metadata": {},
   "source": [
    "### Полезные ссылки\n",
    "- https://www.kaggle.com/code/kanncaa1/time-series-prediction-tutorial-with-eda - ARIMA\n",
    "- https://www.kaggle.com/code/breemen/nyc-taxi-fare-data-exploration - krutoi chel\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (work)",
   "language": "python",
   "name": "speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
