{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e9f85e-e3d8-4612-9688-02fc7eeca391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a7c24c-2851-4bcd-a608-e97ae1b03179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafbadf8-26ab-4ce4-99d2-68d7e7cfc2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialize NVML: Unknown Error\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906b8bb5-e50a-4994-99f1-567899d76a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[1;32m      5\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:408\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    406\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "torch.cuda.set_device(0) \n",
    "torch.backends.cudnn.benchmark = True \n",
    "num_workers = os.cpu_count()\n",
    "torch.set_num_threads(num_workers)\n",
    "ram_gb = psutil.virtual_memory().total / (1024 * 1024 * 1024)\n",
    "batch_size = int(ram_gb / 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c2dddd-957f-4f68-b374-9ec1734188b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552dcd53-4f23-4b3a-aa54-e11815e8864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "def monitor_resources(): # killer ficha NENADO\n",
    "    while True:\n",
    "        print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "        print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacb4fa6-fd86-4e2b-b640-d90c93e32e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1e3bd5-f19b-4f45-9ba5-1cc8b500fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count: 1\n",
      "GPU 0: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb43497-91fd-431c-9241-693d6086b9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from memory_profiler) (6.1.0)\n",
      "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375abe4-deb7-467e-859e-e09133fc6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=10):\n",
    "    from ipywidgets import IntProgress\n",
    "    from IPython.display import display\n",
    "\n",
    "    progress = IntProgress(min=0, max=len(sequence), value=0)\n",
    "    display(progress)\n",
    "    \n",
    "    for index, record in enumerate(sequence):\n",
    "        if index % every == 0:\n",
    "            progress.value = index\n",
    "        yield record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d39cb9-1d18-4254-b155-826a4267ebab",
   "metadata": {},
   "source": [
    "## Sentence transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62072f8-3bee-4ce5-b923-0ea6d66c6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sergeyzh/LaBSE-ru-turbo\")\n",
    "model = AutoModel.from_pretrained(\"sergeyzh/LaBSE-ru-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea94edb-03e5-4c57-83da-ef0e20e581ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8071, 0.9659, 0.6278],\n",
      "        [0.8071, 1.0000, 0.7807, 0.5681],\n",
      "        [0.9659, 0.7807, 1.0000, 0.6036],\n",
      "        [0.6278, 0.5681, 0.6036, 1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0303947 , -0.00513429, -0.01320625, ..., -0.00933791,\n",
       "         0.00857514,  0.01643607],\n",
       "       [ 0.0395426 ,  0.02917142, -0.02478084, ...,  0.02451655,\n",
       "         0.01751278,  0.04843901],\n",
       "       [ 0.02484259, -0.00738657, -0.02211446, ..., -0.00596734,\n",
       "        -0.00914622,  0.00237997],\n",
       "       [-0.00288085, -0.01277977, -0.00787543, ...,  0.02841871,\n",
       "        -0.01064172,  0.01239938]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sergeyzh/LaBSE-ru-turbo\") #вроде норм с ин яз\n",
    "\n",
    "sentences = [\n",
    "    \"Это счастливый человек\",\n",
    "    \"Это счастливая собака\",\n",
    "    \"Это очень счастливый человек\",\n",
    "    \"Сегодня солнечный день\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ec25a-4913-4852-ac16-f1363610ed13",
   "metadata": {},
   "source": [
    "Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61875a74-4a9c-4220-950f-2640ab51906e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92766b706fe4e2191bd67bbc0a452f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778bfa8437504bb1a302d5d888d30331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f9a420dee84837bb687b7ab6e532cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17a7b277e2f48be8a3942b73b6ef29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd796ee572734a499e25259e70e75b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451e9570d3be45efbabe196e71b6d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3017f07807480487eb6ac86bae884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5334ce7ef7ec429d935c4d642e63c785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a780e7e1f3146a39043ef17e4eb03b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf40bd1d46147e39824582333aff105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18845685  0.17425634  0.05447784  0.29051757  0.1676642  -0.04720681\n",
      "   0.64558     0.15980887  0.22689249 -0.03089052  0.25588349 -0.05258771\n",
      "  -0.22610143 -0.05710632  0.13042632  0.12495351  0.31749603  0.19444391\n",
      "  -0.5863255  -0.01258594  0.6099092   0.1643273   0.03331115 -0.27383074\n",
      "  -0.28975755 -0.21119712 -0.02261393 -0.17035922  0.16159014  0.06082741\n",
      "  -0.24162416  0.18579192  0.4274095   0.19295181 -0.07234461  0.16611089\n",
      "   0.10442799  0.20477238  0.21116723  0.1997399  -0.09408264 -0.17383674\n",
      "   0.06427359  0.28025466 -0.29530582  0.06209537  0.1042769  -0.02364421\n",
      "   0.12913182 -0.12617469 -0.17899004  0.0370057  -0.61250603  0.05029817\n",
      "   0.17730355  0.22494122  0.17386058 -0.03840296 -0.21286812  0.25849253\n",
      "  -0.12101638  0.30971512 -0.4196637   0.00907664  0.14188902 -0.30556944\n",
      "   0.17621145 -0.07087357 -0.62033135  0.6770835   0.0172375   0.18405119\n",
      "  -0.16785784  0.20452644 -0.14770274 -0.06175363  0.6301742   0.11120176\n",
      "   0.0515307   0.15927427 -0.05370893  0.05350958  0.1413551   0.11239238\n",
      "  -0.484118   -0.16993618 -0.05321804  0.27650326  0.117777   -0.34912524\n",
      "  -0.5137553  -0.32844043  0.5424045  -0.05326689  0.2291834  -0.01275972\n",
      "   0.10331833 -0.33627793  0.24764974  0.8155242  -0.08930917  0.24757893\n",
      "  -0.12043504  0.01898989  0.32457095 -0.26162416 -0.19714785  0.01440961\n",
      "  -0.03558924 -0.32742968 -0.04829875  0.18030523  0.02312133 -0.14245254\n",
      "  -0.19523911 -0.5549117   0.04145997 -0.08038603 -0.12909932  0.3454117\n",
      "   0.04179803 -0.17788365  0.34458563  0.10763656  0.00641319 -0.8081874\n",
      "   0.18311808 -0.06116287  0.10278972 -0.3596068  -0.12100705 -0.31905478\n",
      "   0.1443448   0.19774662 -0.04758291 -0.13626695  0.27915877  0.10766133\n",
      "  -0.03404961  0.06557185  0.03390286  0.474283    0.03201586  0.43823126\n",
      "  -0.18881223  0.39110145 -0.29364946 -0.09019413 -0.08186892  0.15285046\n",
      "   0.11806724 -0.2978689   0.18289219 -0.23518266 -0.04338417 -0.08308794\n",
      "  -0.01447852  0.08936623  0.11753742 -0.06312162 -0.13069406  0.16051383\n",
      "  -0.07993037  0.04523429 -0.11637418 -0.19606243  0.03943993 -0.34911743\n",
      "  -0.01147587  0.2608548   0.31661972 -0.08063627 -0.18066706  0.02020096\n",
      "  -0.08835123 -0.01678052 -0.38134593  0.15447439 -0.03228491  0.01385772\n",
      "   0.3147257  -0.29187736 -0.11789727 -0.02333075 -0.22907731  0.24850808\n",
      "  -0.08262307  0.17519866  0.07053155  0.17890432 -0.1974804   0.11594963\n",
      "   0.22957727  0.08844819 -0.34138522 -0.00305388  0.44035324  0.20765056\n",
      "  -0.23839886  0.14549936 -0.3251114  -0.04974946  0.08412286 -0.26103276\n",
      "   0.42206785 -0.27341726  0.22958669 -0.18960795 -0.17343746 -0.04636099\n",
      "   0.12553108  0.4785326  -0.55295604  0.21560636  0.069723    0.07278677\n",
      "  -0.23890153  0.1988908  -0.4235429  -0.1645273  -0.22758174 -0.04920306\n",
      "   0.23738693 -0.45531532 -0.06247042  0.5811021  -0.08885644 -0.05396938\n",
      "   0.28655332 -0.4812405  -0.06124134 -0.28116277  0.36897913 -0.29531214\n",
      "  -0.7186567  -0.3877446  -0.16324666  0.13904093 -0.02087943 -0.05228809\n",
      "  -0.10613578 -0.05529149 -0.0638025   0.02985423  0.01341955  0.01263429\n",
      "   0.11067458 -0.07000592 -0.01710519  0.1080922  -0.11134925 -0.42874822\n",
      "  -0.33341154  0.14569521 -0.2426156   0.15181307 -0.08179662  0.24336216\n",
      "  -0.37745428  0.08149572  0.09220822 -0.27653456  0.04063635  0.20002243\n",
      "  -0.0478441  -0.40510842  0.1808856   0.0808125   0.02778461  0.1497763\n",
      "  -0.4525285  -0.06112528  0.2271347  -0.13096145 -0.29849115 -0.15302694\n",
      "  -0.26123837 -0.22188602  0.04267647 -0.20062749 -0.02200276 -0.49436894\n",
      "   0.5353335  -0.02982702 -0.01962641  0.05706301  0.17869143  0.31158453\n",
      "   0.36374244  0.21134542 -0.39374965  0.17488787  0.01140859 -0.10499529\n",
      "  -0.14383791 -0.10661032 -0.4385613   0.04653315 -0.26895496 -0.03211481\n",
      "   0.3126728  -0.2874716  -0.3052496  -0.02647274  0.25250226 -0.18864205\n",
      "   0.21024215  0.07654759 -0.31655517  0.13155574 -0.02851386  0.26622105\n",
      "  -0.4398152   0.33574778 -0.02058756 -0.22813614 -0.18404219  0.15129344\n",
      "  -0.20930634 -0.45565373  0.0973675  -0.17393902 -0.12940054 -0.11562885\n",
      "   0.279103   -0.15251711  0.16353628 -0.18450569 -0.00569287 -0.30151084\n",
      "  -0.10034251  0.33604613 -0.0110164   0.01471767 -0.0762798   0.7871474\n",
      "  -0.28120598 -0.23819903  0.10064658  0.5990075   0.50067765  0.15818895\n",
      "  -0.2903746   0.06542075 -0.14885974  0.06843897 -0.03958024  0.14649293\n",
      "  -0.1463343   0.17913021  0.2805238   0.3625297  -0.31337696 -0.04091791\n",
      "  -0.07653169  0.15323572  0.19257906 -0.37365276  0.09541658 -0.28398466\n",
      "  -0.00148422 -0.04926245  0.44722304  0.657747    0.16523828  0.05867768\n",
      "  -0.40437818 -0.07801342 -0.25537843 -0.36102313 -0.09678137 -0.14205816\n",
      "   0.14746182  0.09517755  0.05682942 -0.17478289  0.26147893  0.14114736\n",
      "   0.12460976  0.08857521  0.18453875  0.2709023   0.3476951   0.08729663]\n",
      " [ 0.3470767   0.17975073  0.11288972 -0.22380027 -0.0293752   0.00868651\n",
      "   0.5688569  -0.17423813  0.15573622  0.05918537  0.04771047  0.11906723\n",
      "   0.06961228 -0.39164922 -0.11649477  0.39683256 -0.16703579  0.42248803\n",
      "  -0.6075648  -0.2320915   0.06476653  0.16615856 -0.23384619 -0.11623362\n",
      "   0.09024548  0.33958396 -0.16615486 -0.29775563 -0.0145021  -0.31055215\n",
      "  -0.02961079  0.44532555  0.44516328 -0.01631257 -0.12811206  0.29556146\n",
      "  -0.44812793  0.38878626  0.165114    0.12342686 -0.3238552  -0.08443239\n",
      "   0.17806557  0.05183274  0.31275326  0.06461035 -0.3461043  -0.01012807\n",
      "  -0.07875679  0.31033972 -0.10869153  0.07183908 -0.48495167  0.5769386\n",
      "   0.13360119  0.02629794 -0.25099748  0.37116382 -0.10699216 -0.17746435\n",
      "  -0.09543918  0.18270274 -0.52960604  0.22841324 -0.02978982 -0.13325116\n",
      "   0.35409585 -0.00828859 -0.24981046  0.53161824 -0.17178164  0.09505121\n",
      "   0.27921164 -0.36492947 -0.15713847  0.288723    0.20304184  0.05974204\n",
      "   0.13127656  0.05664804 -0.06217051  0.2146627   0.11609121 -0.3990603\n",
      "   0.11946708 -0.24893887 -0.1325681   0.44654885  0.3125725  -0.3931335\n",
      "  -0.17129146 -0.5401934   0.7123145   0.08043351  0.17059132 -0.06945714\n",
      "  -0.18228093 -0.3724777   0.5619806   0.36433625 -0.08759411  0.545848\n",
      "  -0.03697028 -0.05890995 -0.26084924 -0.2623256  -0.07935369  0.32174796\n",
      "   0.14701362 -0.18558    -0.3206958   0.23243836  0.30205423 -0.08602177\n",
      "   0.0082017  -0.15061198  0.27068552 -0.331727    0.00814692  0.7361279\n",
      "  -0.01074319  0.09526201  0.03116515  0.16779831 -0.09472425 -0.32779145\n",
      "   0.15817592 -0.11084623 -0.07533924 -0.2856407   0.08807824  0.12668458\n",
      "  -0.0541715   0.13834663 -0.17383303 -0.1796138   0.1591357  -0.13249199\n",
      "  -0.02498725 -0.02863709  0.22149894  0.41240937 -0.09995215  0.3916578\n",
      "  -0.03023202  0.19657299 -0.5089572  -0.13262276 -0.08178656  0.31298605\n",
      "  -0.24409048 -0.15581366 -0.27632198 -0.2603111   0.02606717  0.15951855\n",
      "  -0.02367788 -0.05711327 -0.21294382  0.0817499  -0.08173864  0.19129178\n",
      "  -0.29870176  0.19334705  0.26285166  0.07807028  0.08929737  0.18175292\n",
      "  -0.24137028 -0.00128371  0.5129107  -0.24898422 -0.2827513  -0.32939053\n",
      "  -0.27734903  0.30010805 -0.10644297  0.14977673  0.20152768  0.14604995\n",
      "   0.08155494 -0.15151127 -0.36765543  0.28511232 -0.20097058  0.04080797\n",
      "  -0.4555478   0.08342902 -0.07359831  0.295878    0.05567523 -0.3490296\n",
      "   0.0990178  -0.01793128 -0.25333762 -0.05929412  0.21367724  0.21086904\n",
      "  -0.5560664   0.12414751  0.04703007  0.06113534 -0.00192894 -0.4775996\n",
      "   0.18244493  0.07414564 -0.39272007 -0.17483972 -0.0664869   0.28929192\n",
      "  -0.00717126  0.13004668  0.34543553  0.00546772  0.27574146  0.07198471\n",
      "  -0.00558614 -0.22266832  0.02625488 -0.3982286   0.16638324 -0.38634893\n",
      "   0.36284992 -0.21355103 -0.21243015  0.66783863 -0.19671014  0.3209358\n",
      "  -0.17523853 -0.31116727 -0.26940373 -0.0679432   0.05132945 -0.43308282\n",
      "  -0.06844477 -0.25163177 -0.23884174  0.04973104 -0.18011372  0.02875861\n",
      "   0.10885779  0.3992664   0.01026716  0.04654568  0.0442544   0.18722235\n",
      "  -0.06429294  0.05355747 -0.15590559 -0.10054191  0.29329872 -0.0483566\n",
      "   0.02299042  0.3100093  -0.06247506  0.02948101 -0.32953897  0.5130008\n",
      "  -0.34651613 -0.19149873  0.2618857  -0.02514721 -0.10117875  0.69044226\n",
      "   0.28683922 -0.42476043 -0.3400454  -0.02383409  0.03670345 -0.2145779\n",
      "  -0.3135756   0.06676682 -0.06548522 -0.14639929  0.18192545 -0.15907076\n",
      "  -0.49846765 -0.21165809  0.11630958 -0.2699258   0.16266482 -0.64319384\n",
      "   0.32003587  0.08476799 -0.00833978  0.13469389  0.20395769 -0.04883527\n",
      "   0.2293457   0.12962982 -0.28847146 -0.01838065  0.16635731 -0.2572393\n",
      "  -0.18950164  0.26680577 -0.53406245  0.0329741  -0.16005264 -0.3482897\n",
      "  -0.13480654 -0.07903051 -0.40037203  0.2391489  -0.18939853 -0.22996104\n",
      "  -0.26500922  0.3055     -0.2157781   0.12839954  0.22074066  0.02465545\n",
      "  -0.37391227  0.3478063  -0.16085577 -0.035237    0.19708762  0.05138609\n",
      "  -0.24489084  0.04642856  0.1059614  -0.0390306  -0.39346662  0.3539262\n",
      "   0.26167664 -0.2030544   0.06714197 -0.29006293  0.21563104 -0.11339241\n",
      "  -0.11325756  0.5838538  -0.3625656   0.09554892 -0.1885096   0.52210647\n",
      "   0.01045473  0.08855112 -0.19684866  0.5222598   0.58784324  0.0795956\n",
      "  -0.18018734 -0.0291261  -0.11641084  0.33799312  0.1357159   0.01027521\n",
      "  -0.40844613 -0.17475618  0.12402979  0.12424014 -0.21745622  0.26906404\n",
      "  -0.10524534 -0.06161266  0.4625974  -0.15411493  0.23713923  0.18526663\n",
      "   0.09552387 -0.40052667  0.0371739   0.28664222 -0.2980817  -0.22483231\n",
      "  -0.13735828 -0.2155528  -0.02228152 -0.22343767 -0.21233957  0.1121263\n",
      "   0.06114585 -0.27714592  0.2833104  -0.25338364  0.6110291   0.34967223\n",
      "   0.27692598  0.17295039 -0.18559723  0.31266668  0.02952214 -0.27695543]]\n"
     ]
    }
   ],
   "source": [
    "#pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8cb93-5496-49d1-bf36-89fa79198dcd",
   "metadata": {},
   "source": [
    "## Zero-shot text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c05da8e-cf0e-4fc3-8ac2-44c7cba4b6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fdd925d48d4af8b3c67f2121b3cbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e8d49df7344f25aaff5adc834b6df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3b2bf1f18d4aa68a572d19b06add90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b3c92c9f1641eb834d5bf184de0b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a78859cf9c54a4eaf62ae77e99422b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 19:06:26.977994: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-09 19:06:26.978041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-09 19:06:26.979301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-09 19:06:27.074705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-09 19:06:30.093669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f3ecfb8bda4b34b561eb229806b529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 0.009525914, 'contradiction': 0.9332064, 'neutral': 0.057267707}\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers sentencepiece --quiet\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "text1 = 'Сократ - человек, а все люди смертны.'\n",
    "text2 = 'Сократ никогда не умрёт.'\n",
    "with torch.inference_mode():\n",
    "    out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n",
    "    proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n",
    "print({v: proba[k] for k, v in model.config.id2label.items()})\n",
    "# {'entailment': 0.009525929, 'contradiction': 0.9332064, 'neutral': 0.05726764}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d895b1-025b-4740-8901-92243824a626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9059289 , 0.09407106], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_zero_shot(text, label_texts, model, tokenizer, label='entailment', normalize=True):\n",
    "    label_texts\n",
    "    tokens = tokenizer([text] * len(label_texts), label_texts, truncation=True, return_tensors='pt', padding=True)\n",
    "    with torch.inference_mode():\n",
    "        result = torch.softmax(model(**tokens.to(model.device)).logits, -1)\n",
    "    proba = result[:, model.config.label2id[label]].cpu().numpy()\n",
    "    if normalize:\n",
    "        proba /= sum(proba)\n",
    "    return proba\n",
    "classes = ['Я доволен', 'Я недоволен']\n",
    "predict_zero_shot('Какая гадость эта ваша заливная рыба!', classes, model, tokenizer)\n",
    "# array([0.05609814, 0.9439019 ], dtype=float32)\n",
    "predict_zero_shot('Какая вкусная эта ваша заливная рыба!', classes, model, tokenizer)\n",
    "# array([0.9059292 , 0.09407079], dtype=float32)\n",
    "\n",
    "\n",
    "def predict_zero_shot_df(df, classes, model, tokenizer, label='entailment', normalize=True):\n",
    "    predictions = []\n",
    "    for text in df['text']:  \n",
    "        tokens = tokenizer([text] * len(classes), classes, truncation=True, return_tensors='pt', padding=True)\n",
    "        with torch.inference_mode():\n",
    "            result = torch.softmax(model(**tokens.to(model.device)).logits, -1)\n",
    "        proba = result[:, model.config.label2id[label]].cpu().numpy()\n",
    "        if normalize:\n",
    "            proba /= sum(proba)\n",
    "        # Получаем класс с максимальной вероятностью\n",
    "        pred_class = classes[proba.argmax()]\n",
    "        predictions.append(pred_class)\n",
    "    return predictions\n",
    "\n",
    "# preds = predict_zero_shot_df(test, df.target.unique(), model, tokenizer)\n",
    "# subm['target'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2079d-f0b5-4939-8d57-3dc003ba0e9c",
   "metadata": {},
   "source": [
    "English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb075bb-fea0-47e2-8102-97330a4a3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)\n",
    "#{'labels': ['travel', 'dancing', 'cooking'],\n",
    "# 'scores': [0.9938651323318481, 0.0032737774308770895, 0.002861034357920289],\n",
    "# 'sequence': 'one day I will see the world'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8abcaf-ef79-4afd-8ab6-7a562e701262",
   "metadata": {},
   "source": [
    "### Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19804137-bbd1-4f31-a9ac-e25cae01ff01",
   "metadata": {},
   "source": [
    "- https://huggingface.co/ai-forever/sbert_large_nlu_ru\n",
    "- https://huggingface.co/cointegrated/rubert-tiny2 \n",
    "- https://github.com/Vlad15lav/food-recsys/blob/main/notebooks/demo_bert_recsys.ipynb\n",
    "- https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.ZeroShotClassificationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12daa4e1-3ce9-429e-9e8f-e26f6a91469a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
